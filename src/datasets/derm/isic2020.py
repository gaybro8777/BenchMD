import os
from typing import Any

import numpy as np
import pandas as pd
import torch
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from torchvision.datasets.utils import download_and_extract_archive, extract_archive

from src.datasets.specs import Input2dSpec

TRAIN_SPLIT_RATIO = 0.8


def any_exist(files):
    return any(map(os.path.exists, files))


class ISIC2020(Dataset):
    # Dataset information.
    """
    The dataset contains 33,126 dermoscopic training images of unique benign and malignant skin lesions from over 2,000 patients. Each image is associated with one of these individuals using a unique patient identifier. All malignant diagnoses have been confirmed via histopathology, and benign diagnoses have been confirmed using either expert agreement, longitudinal follow-up, or histopathology. 
    
    The dataset was generated by the International Skin Imaging Collaboration (ISIC) and images are from the following sources: Hospital ClÃ­nic de Barcelona, Medical University of Vienna, Memorial Sloan Kettering Cancer Center, Melanoma Institute Australia, University of Queensland, and the University of Athens Medical School.
    
    After download, put your files under a folder called isic2020, then under a folder called dermatology under your data root.
    """
    NUM_CLASSES = 2
    INPUT_SIZE = (224, 224)
    PATCH_SIZE = (16, 16)
    IN_CHANNELS = 3

    def __init__(self, base_root: str, download: bool = False, train: bool = True) -> None:
        super().__init__()
        self.root = os.path.join(base_root, 'derm', 'isic2020')
        self.download = download
        self.index_location = self.find_data()
        self.split = 'train' if train else 'valid'
        self.build_index()
        self.TRANSFORMS = transforms.Compose(
            [
                transforms.Resize(self.INPUT_SIZE[0] - 1, max_size=self.INPUT_SIZE[0]),
                transforms.ToTensor(),
                transforms.Normalize([0.8061, 0.6211, 0.5912], [0.1491, 0.1756, 0.2016])
            ]
        )

    def find_data(self):
        os.makedirs(self.root, exist_ok=True)

        zip_file = os.path.join(self.root, 'ISIC_2020_Training.zip')
        folder = os.path.join(self.root, 'ISIC_2020_Training')
        # if no data is present, prompt the user to download it
        if not any_exist([zip_file, folder]):
            if self.download == True:
                self.download_dataset()

            else:
                raise RuntimeError(
                    """
                ISIC2020 data not downloaded,  You can use download=True to download it
                """
                )

        # if the data has not been extracted, extract the data

        if not os.path.exists(folder):
            print('Extracting data...')
            extract_archive(zip_file)
            print('Done')

        # return the data folder
        return folder

    def download_dataset(self):
        '''Download the dataset if not exists already'''

        # download and extract files
        print('Downloading and Extracting...')

        filename = "ISIC_2020_Training.zip"
        download_and_extract_archive(
            "https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip",
            download_root=self.root,
            filename=filename
        )

        print('Done!')

    def build_index(self):
        print('Building index...')
        index_file = os.path.join(self.root, 'ISIC_2020_Training_GroundTruth.csv')
        df = pd.read_csv(index_file)

        df['image_name'] = df['image_name'].apply(lambda s: os.path.join(self.root, 'ISIC_2020_Training/' + s + '.jpg'))

        # Split into train/val
        cols = ['benign_malignant']
        index_file = df.copy()
        index = pd.DataFrame(columns=index_file.columns)
        for c in cols:
            unique_counts = index_file[c].value_counts()
            for c_value, _ in unique_counts.items():
                df_sub = index_file[index_file[c] == c_value]
                g = df_sub.sample(frac=TRAIN_SPLIT_RATIO, replace=False)
                index = index.append(g)
        index_file = index.reset_index(drop=True)
        if self.split != 'train':
            index_file = pd.concat([df, index_file]).drop_duplicates(keep=False)
        df = index_file.reset_index(drop=True)
        self.fnames = df['image_name'].to_numpy()
        self.labels = (df['benign_malignant'] == 'malignant').to_numpy().astype(np.int)
        print('Done')

    def __len__(self) -> int:
        return self.fnames.shape[0]

    def __getitem__(self, index: int) -> Any:
        fname = self.fnames[index]
        image = Image.open(os.path.join(self.root, fname)).convert('RGB')
        img = self.TRANSFORMS(image)
        _, h, w = np.array(img).shape
        if h > w:
            dim_gap = img.shape[1] - img.shape[2]
            pad1, pad2 = dim_gap // 2, (dim_gap + (dim_gap % 2)) // 2
            img = transforms.Pad((pad1, 0, pad2, 0))(img)
        elif h == w:
            #edge case 223,223,  resize to match 224*224
            dim_gap = self.INPUT_SIZE[0] - h
            pad1, pad2 = dim_gap, dim_gap
            img = transforms.Pad((pad1, pad2, 0, 0))(img)
        else:
            dim_gap = img.shape[2] - img.shape[1]
            pad1, pad2 = dim_gap // 2, (dim_gap + (dim_gap % 2)) // 2
            img = transforms.Pad((0, pad1, 0, pad2))(img)
        label = torch.tensor(self.labels[index]).long()
        return index, img.float(), label

    @staticmethod
    def num_classes():
        return ISIC2020.NUM_CLASSES

    @staticmethod
    def spec():
        return [
            Input2dSpec(input_size=ISIC2020.INPUT_SIZE, patch_size=ISIC2020.PATCH_SIZE, in_channels=ISIC2020.IN_CHANNELS),
        ]
