dataset:
  loss: cross_entropy
  metric: auroc
  name: ptbxl
  batch_size: 128
  num_workers: 32
model:
  name: transformer
  kwargs:
    embed_dim: 256
    out_dim: 128
    dim: 256
    depth: 12
    heads: 8
    mlp_dim: 512
    pool: mean
    dim_head: 64
    dropout: 0.1
    emb_dropout: 0.1
ckpt: /home/ubuntu/tutorial/tutorial-ecg-mae/epoch14-step1999.ckpt
finetune_size: medium
test: false
data_root: /home/ubuntu/BenchMD/src/datasets
gpus: 0
exp:
  base_dir: /home/ubuntu/tutorial/
  name: tutorial-ecg-mae-finetune
trainer:
  weights_summary: top
  seed: 0
  val_check_interval: 1.0
  limit_val_batches: 1.0
  precision: 16
  max_epochs: 1
  gradient_clip_val: 0
optim:
  name: adam
  lr: 0.0001
  weight_decay: 0.0001
  momentum: 0.9
